{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhay-8/Image-Processing/blob/main/IP_J_Comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "589jsEKdASPn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb-1_VqdC4LI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask_restful"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhJKok9PL1VB",
        "outputId": "521d8b1b-fe19-4ab0-ff03-c6a6f3a80111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting flask_restful\n",
            "  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_restful) (2.2.4)\n",
            "Collecting aniso8601>=0.82\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from flask_restful) (1.16.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from flask_restful) (2022.7.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_restful) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_restful) (8.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_restful) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_restful) (2.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_restful) (2.1.2)\n",
            "Installing collected packages: aniso8601, flask_restful\n",
            "Successfully installed aniso8601-9.0.1 flask_restful-0.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AR40lbE5ZEIv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca1ecf20-0a22-4001-b5d8-3e8fea0f08e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7Xx1s5CM3mC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b17558df-cc9e-4628-e4e1-ce5c0629f46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Image Processing\n"
          ]
        }
      ],
      "source": [
        "%cd gdrive/MyDrive/Image Processing\n",
        "# !unzip \"/content/gdrive/My Drive/Image Processing/archive.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "from flask_restful import reqparse, abort, Api, Resource\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "app = Flask(__name__)\n",
        "api = Api(app)\n",
        "\n",
        "\n",
        "model = tf.keras.models.load_model('./version3.h5')"
      ],
      "metadata": {
        "id": "MP5_hSCKMPov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow0doqU0RK_B"
      },
      "outputs": [],
      "source": [
        "labels = pd.read_csv('/content/gdrive/MyDrive/Image Processing/dataset/semantic_drone_dataset/class_dict_seg.csv')\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR0awlK2bPhC"
      },
      "outputs": [],
      "source": [
        "labels.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYTGGVtVbSgG"
      },
      "outputs": [],
      "source": [
        "def print_label_colors():\n",
        "  for index, label in enumerate(labels.name):\n",
        "    plt.subplot(6, 4, index+1)\n",
        "    (r,g,b) = labels.iloc[index].values[1:]\n",
        "    img_ = np.array([[[r,g,b], [r,g,b], [r,g,b], [r,g,b]]])\n",
        "    plt.title(label)\n",
        "    plt.imshow(img_)\n",
        "    plt.axis('off')\n",
        "\n",
        "print_label_colors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBQkaBnGhQH-"
      },
      "outputs": [],
      "source": [
        "img1 = cv2.imread('/content/gdrive/MyDrive/Image Processing/dataset/semantic_drone_dataset/original_images/000.jpg')\n",
        "plt.imshow(img1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEesdexHhjSz"
      },
      "outputs": [],
      "source": [
        "img2 = cv2.imread('/content/gdrive/MyDrive/Image Processing/dataset/semantic_drone_dataset/label_images_semantic/000.png')\n",
        "plt.imshow(img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHkYJSMFagS0"
      },
      "outputs": [],
      "source": [
        "num_classes=23\n",
        "H=800\n",
        "W=1200\n",
        "\n",
        "def read_image(x):\n",
        "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32) ##image dtype is Float32\n",
        "    return x\n",
        "\n",
        "\n",
        "def read_mask(x):\n",
        "    x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x.astype(np.int32) ##mask dtype is Int32\n",
        "    return x\n",
        "\n",
        "\n",
        "def tf_dataset(x,y, batch=4):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x,y)) # Dataset data object created from input and target data\n",
        "    dataset = dataset.shuffle(buffer_size=100) ## selected from the first 100 samples\n",
        "    dataset = dataset.map(preprocess) # Applying preprocessing to every batch in the Dataset object\n",
        "    dataset = dataset.batch(batch) # Determine batch-size\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(2) # Optimization to reduce waiting time on each object\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def preprocess(x,y):\n",
        "    def f(x,y):\n",
        "        x = x.decode() ##byte stream conversion\n",
        "        y = y.decode()\n",
        "        image = read_image(x)\n",
        "        mask = read_mask(y)\n",
        "        return image, mask\n",
        "\n",
        "    image, mask = tf.numpy_function(f,[x,y],[tf.float32, tf.int32])\n",
        "    mask = tf.one_hot(mask, num_classes, dtype=tf.int32)\n",
        "    image.set_shape([H, W, 3])    # In the Images, number of channels = 3.\n",
        "    mask.set_shape([H, W, num_classes])    # In the Masks, number of channels = number of classes.\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZapBcd_aj50"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/gdrive/MyDrive/Image Processing/dataset/semantic_drone_dataset'\n",
        "img_path = root_dir + '/original_images/'\n",
        "mask_path = root_dir + '/label_images_semantic/'\n",
        "\n",
        "names = list(map(lambda x: x.replace('.jpg', ''), os.listdir(img_path)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL9MKSfrayh8",
        "outputId": "72e4e705-7ddb-4850-85c6-19d8020b9e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Size : 288 images\n",
            "Val Size   :  72 images\n",
            "Test Size  :  40 images\n"
          ]
        }
      ],
      "source": [
        "X_trainval, X_test = train_test_split(names, test_size=0.1, random_state=19)\n",
        "X_train, X_val = train_test_split(X_trainval, test_size=0.2, random_state=19)\n",
        "\n",
        "print(f\"Train Size : {len(X_train)} images\")\n",
        "print(f\"Val Size   :  {len(X_val)} images\")\n",
        "print(f\"Test Size  :  {len(X_test)} images\")\n",
        "\n",
        "y_train = X_train\n",
        "y_test = X_test\n",
        "y_val = X_val\n",
        "\n",
        "img_train = [os.path.join(img_path, f\"{name}.jpg\") for name in X_train]\n",
        "mask_train = [os.path.join(mask_path, f\"{name}.png\") for name in y_train]\n",
        "img_val = [os.path.join(img_path, f\"{name}.jpg\") for name in X_val]\n",
        "mask_val = [os.path.join(mask_path, f\"{name}.png\") for name in y_val]\n",
        "img_test = [os.path.join(img_path, f\"{name}.jpg\") for name in X_test]\n",
        "mask_test = [os.path.join(mask_path, f\"{name}.png\") for name in y_test]\n",
        "\n",
        "batch_size=3\n",
        "\n",
        "train_dataset = tf_dataset(img_train, mask_train, batch = batch_size)\n",
        "valid_dataset = tf_dataset(img_val, mask_val, batch = batch_size)\n",
        "\n",
        "train_steps = len(img_train)//batch_size\n",
        "valid_steps = len(img_val)//batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQqXtBNoa5YR",
        "outputId": "af538d81-7252-4ae1-f8e6-e22f8d380ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n"
          ]
        }
      ],
      "source": [
        "print(train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8P4bUpra9K-"
      },
      "outputs": [],
      "source": [
        "num_classes=23\n",
        "H=800\n",
        "W=1200\n",
        "\n",
        "\n",
        "def test_dataset(x, batch=32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(x)\n",
        "    dataset = dataset.map(preprocess_test)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(2)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def preprocess_test(x):\n",
        "    def f(x):\n",
        "        x = x.decode()\n",
        "        image = read_image(x)\n",
        "        return image\n",
        "\n",
        "    image = tf.convert_to_tensor(tf.numpy_function(f, [x] , [tf.float32]))\n",
        "    image = tf.reshape(image, (H, W, 3))    # In the Images, number of channels = 3.\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPr8hmNqbBTW"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "\n",
        "\n",
        "def multi_unet_model(n_classes=23, IMG_HEIGHT=800, IMG_WIDTH=1200, IMG_CHANNELS=3):\n",
        "#Build the model\n",
        "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "    s = inputs\n",
        "\n",
        "    #Contraction path\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)  # Original 0.1\n",
        "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)  # Original 0.1\n",
        "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.1)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.1)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "\n",
        "    #Expansive path\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.1)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)  # Original 0.1\n",
        "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)  # Original 0.1\n",
        "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(n_classes, (1, 1), activation='softmax')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    #NOTE: Compile the model in the main program to make it easy to test with various loss functions\n",
        "    model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azNzCbxTbF8t"
      },
      "outputs": [],
      "source": [
        "model = multi_unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka2MlImfbIov"
      },
      "outputs": [],
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(min_delta=0.001, patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MfaBaT2Gy-7_"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset,\n",
        "          steps_per_epoch=train_steps,\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=valid_steps,\n",
        "          epochs=100\n",
        "         )\n",
        "\n",
        "history.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPvBA_m8n4YF"
      },
      "outputs": [],
      "source": [
        "model =  tf.keras.models.load_model('/content/gdrive/MyDrive/Image Processing/version3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model['val_loss'], label='val', marker='o')\n",
        "plt.plot(model['train_loss'], label='train', marker='o')\n",
        "plt.title('Loss per epoch'); plt.ylabel('loss');\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(), plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QJ_A_xzd7hSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piopxJbaoKRY"
      },
      "outputs": [],
      "source": [
        "test_ds = tf_dataset(img_test, mask_test, batch = batch_size)\n",
        "model.evaluate(test_ds, steps=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK-977y8oL_f"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(test_dataset(img_test, batch = 1), steps=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zpetqrToNbu"
      },
      "outputs": [],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxBcTgywoRyM"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(pred, axis=3)\n",
        "label = np.array([cv2.resize(cv2.imread(mask_path+img_test[i][-7:-4]+'.png')[:, :, 0], (1200, 800)) for i in range(predictions.shape[0])])\n",
        "label = label.flatten()\n",
        "predictions = predictions.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-HXGvQCoTce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Image Processing/dataset/semantic_drone_dataset/class_dict_seg.csv')\n",
        "cm = confusion_matrix(label, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaYv8FctoUux"
      },
      "outputs": [],
      "source": [
        "df_cm = pd.DataFrame(cm)\n",
        "df_cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "df_cm = pd.DataFrame(df_cm, index = label,  columns = label)\n",
        "plt.figure(figsize = (40,40))\n",
        "# sns.heatmap(df_cm, annot=True)\n",
        "sns.heatmap(df_cm/np.sum(df_cm), annot=True,\n",
        "            fmt='.1%', cmap='Oranges')\n",
        "plt.xlabel('Predicted',fontsize=22)\n",
        "plt.ylabel('Actual',fontsize=22)\n",
        "# plt.savefig('plot.png')"
      ],
      "metadata": {
        "id": "IIAU9oze-Iiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liEx52BVoWK2"
      },
      "outputs": [],
      "source": [
        "cmap = np.array(list(df[[' r', ' g', ' b']].transpose().to_dict('list').values()))\n",
        "predictions = predictions.reshape(-1, 800, 1200)\n",
        "label = label.reshape(-1, 800, 1200)\n",
        "\n",
        "i = 18\n",
        "\n",
        "fig, ax = plt.subplots(3, 2, figsize=(15, 15))\n",
        "for j in range(3):\n",
        "    ax[j, 0].imshow(cmap[predictions[i+j]])\n",
        "    ax[j, 1].imshow(cmap[label[i+j]])\n",
        "    ax[j, 0].set_title('Prediction')\n",
        "    ax[j, 1].set_title('Ground truth')\n",
        "    ax[j, 0].grid(False)\n",
        "    ax[j, 1].grid(False)\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}